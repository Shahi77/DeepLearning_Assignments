{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahi77/DeepLearning_Assignments/blob/main/Assignment05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkG6AxgjBNO"
      },
      "source": [
        "VOC2012"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZWM-ULLmiH8",
        "outputId": "0f575c2d-061f-49ef-d267-d78621342b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.2202\n",
            "Epoch 2/5, Loss: 0.1943\n",
            "Epoch 3/5, Loss: 0.1806\n",
            "Epoch 4/5, Loss: 0.1681\n",
            "Epoch 5/5, Loss: 0.1557\n",
            "Accuracy: 0.3215, Hamming Loss: 0.0523, Precision: 0.7502, Recall: 0.4324, F1-score: 0.4668, Jaccard Index: 0.3433\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Define VOC 2012 class labels (20 classes)\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "# Initialize and fit MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])  # Fit with all possible classes\n",
        "\n",
        "# Define Data Augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset Wrapper for Multi-Label Classification\n",
        "class VOCMultiLabelDataset(Dataset):\n",
        "    def __init__(self, root=\"./data\", year=\"2012\", image_set=\"train\", transform=None):\n",
        "        self.dataset = datasets.VOCDetection(root=root, year=year, image_set=image_set, download=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        objects = target[\"annotation\"][\"object\"]\n",
        "\n",
        "        # If only one object exists, wrap it in a list\n",
        "        if isinstance(objects, dict):\n",
        "            objects = [objects]\n",
        "\n",
        "        labels = [obj[\"name\"] for obj in objects]\n",
        "\n",
        "        # Convert labels to one-hot encoding\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Load Datasets\n",
        "train_dataset = VOCMultiLabelDataset(transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)# Set num_workers=0 for Colab\n",
        "\n",
        "# Define Multi-Label Classification Model\n",
        "class MultiLabelResNet(nn.Module):\n",
        "    def __init__(self, num_classes=20):\n",
        "        super(MultiLabelResNet, self).__init__()\n",
        "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Correct way to load pretrained model\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()  # For multi-label classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.model(x))\n",
        "\n",
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiLabelResNet(num_classes=20).to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    wandb.log({\"Loss\": running_loss / len(train_dataloader)})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "h_loss = hamming_loss(y_true, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "jaccard = jaccard_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Log to wandb\n",
        "wandb.log({\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Hamming Loss\": h_loss,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1-score\": f1,\n",
        "    \"Jaccard Index\": jaccard\n",
        "})\n",
        "\n",
        "# Print Metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}, Hamming Loss: {h_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Jaccard Index: {jaccard:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_4gNuFtR17J",
        "outputId": "5c1291e2-92cf-4a35-af7c-87933a4b8281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
            "Epoch 1/5, Loss: 0.1672\n",
            "Epoch 2/5, Loss: 0.1372\n",
            "Epoch 3/5, Loss: 0.1286\n",
            "Epoch 4/5, Loss: 0.1191\n",
            "Epoch 5/5, Loss: 0.1125\n",
            "Model: MobileNetV2, Dropout: 0.3, Augmentation: strong, Image Size: 224\n",
            "Accuracy: 0.5403, Hamming Loss: 0.0332, Precision: 0.8530, Recall: 0.6556, F1-score: 0.7273, Jaccard Index: 0.5859\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Define VOC 2012 class labels (20 classes)\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])\n",
        "\n",
        "# Define Multiple Data Augmentation Strategies\n",
        "augmentation_setups = {\n",
        "    \"basic\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"strong\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Function to Select Model\n",
        "def get_model(model_name, num_classes=20, dropout_rate=0.3):\n",
        "    if model_name == \"ResNet18\":\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.fc.in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    elif model_name == \"MobileNetV2\":\n",
        "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
        "        model.classifier[1] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.classifier[1].in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    elif model_name == \"EfficientNet-B0\":\n",
        "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "        model.classifier[1] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.classifier[1].in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Model not supported\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Custom Dataset Wrapper\n",
        "class VOCMultiLabelDataset(Dataset):\n",
        "    def __init__(self, root=\"./data\", year=\"2012\", image_set=\"train\", transform=None):\n",
        "        self.dataset = datasets.VOCDetection(root=root, year=year, image_set=image_set, download=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        objects = target[\"annotation\"][\"object\"]\n",
        "        if isinstance(objects, dict):  # Convert single object dict to list\n",
        "            objects = [objects]\n",
        "        labels = [obj[\"name\"] for obj in objects]\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Experiment Parameters (Change these)\n",
        "model_name = \"MobileNetV2\"  # Try: \"ResNet18\", \"MobileNetV2\", \"EfficientNet-B0\"\n",
        "dropout_rate = 0.3  # Try: 0.1, 0.3, 0.5\n",
        "augmentation_type = \"strong\"  # Try: \"basic\", \"strong\"\n",
        "image_size = 224  # Try: 128, 224, 256, 384\n",
        "\n",
        "# Set Transform\n",
        "transform = augmentation_setups[augmentation_type]\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = VOCMultiLabelDataset(transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model(model_name, dropout_rate=dropout_rate).to(device)\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    wandb.log({\"Loss\": running_loss / len(train_dataloader)})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "h_loss = hamming_loss(y_true, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "jaccard = jaccard_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Log to wandb\n",
        "wandb.log({\n",
        "    \"Model\": model_name,\n",
        "    \"Dropout Rate\": dropout_rate,\n",
        "    \"Augmentation\": augmentation_type,\n",
        "    \"Image Size\": image_size,\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Hamming Loss\": h_loss,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1-score\": f1,\n",
        "    \"Jaccard Index\": jaccard\n",
        "})\n",
        "\n",
        "# Print Metrics\n",
        "print(f\"Model: {model_name}, Dropout: {dropout_rate}, Augmentation: {augmentation_type}, Image Size: {image_size}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}, Hamming Loss: {h_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Jaccard Index: {jaccard:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oEikNX8i-67"
      },
      "source": [
        "PASCAL-VOC2007"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mxhdzeI7W-A7",
        "outputId": "5760eb0d-6d30-4fa6-dd1b-39eda969ea11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250309_054606-caqhzmag</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/caqhzmag' target=\"_blank\">efficient-surf-24</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/caqhzmag' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/caqhzmag</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar to ./data/VOCtrainval_06-Nov-2007.tar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 460M/460M [00:32<00:00, 14.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/VOCtrainval_06-Nov-2007.tar to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.2216, Accuracy: 0.1020\n",
            "Epoch 2/5, Loss: 0.1887, Accuracy: 0.1591\n",
            "Epoch 3/5, Loss: 0.1741, Accuracy: 0.2063\n",
            "Epoch 4/5, Loss: 0.1674, Accuracy: 0.2299\n",
            "Epoch 5/5, Loss: 0.1587, Accuracy: 0.2667\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Dataset Selection\n",
        "dataset_name = \"PASCAL-VOC2007\"  # Choose from [\"NUS-WIDE\", \"MS-COCO\", \"PASCAL-VOC2007\", \"VOC2012\", \"Visual Genome\", \"News-500\", \"CUB\"]\n",
        "\n",
        "# Define Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define MultiLabelBinarizer\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])  # Fix NotFittedError\n",
        "\n",
        "# Custom Dataset Class\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, root, dataset_name, transform=None):\n",
        "        if dataset_name == \"VOC2012\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2012\", image_set=\"train\", download=True)\n",
        "        elif dataset_name == \"PASCAL-VOC2007\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2007\", image_set=\"train\", download=True)\n",
        "        else:\n",
        "            raise ValueError(\"Dataset not supported yet!\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        labels = [obj[\"name\"] for obj in target[\"annotation\"][\"object\"]]\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = MultiLabelDataset(root=\"./data\", dataset_name=dataset_name, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define Model Options\n",
        "model_choices = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"mobilenet_v2\": models.mobilenet_v2,\n",
        "    \"vgg16\": models.vgg16,\n",
        "    \"densenet121\": models.densenet121,\n",
        "    \"alexnet\": models.alexnet,\n",
        "    \"googlenet\": models.googlenet\n",
        "}\n",
        "model_name = \"resnet18\"  # Choose model\n",
        "\n",
        "# Define Multi-Label Classification Model\n",
        "class MultiLabelModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=20, dropout_rate=0.5):\n",
        "        super(MultiLabelModel, self).__init__()\n",
        "        self.model = model_choices[model_name](pretrained=True)\n",
        "        if \"fc\" in dir(self.model):\n",
        "            in_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            in_features = self.model.classifier[6].in_features\n",
        "            self.model.classifier[6] = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.model(x))\n",
        "\n",
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiLabelModel(model_name=model_name, num_classes=20, dropout_rate=0.3).to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "train_losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        predictions = (outputs > 0.5).float()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "    avg_loss = running_loss / len(train_dataloader)\n",
        "    accuracy = accuracy_score(np.array(y_true), np.array(y_pred))\n",
        "    train_losses.append(avg_loss)\n",
        "    accuracies.append(accuracy)\n",
        "    wandb.log({\"Loss\": avg_loss, \"Accuracy\": accuracy})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Plot Loss and Accuracy Curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, marker='o', linestyle='-', color='b', label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), accuracies, marker='s', linestyle='-', color='r', label='Training Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metrics\")\n",
        "plt.title(\"Training Loss and Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nSTt-RtUG4p-",
        "outputId": "4b540ab9-4625-4801-cfd0-77becfaa7eed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250309_181456-rm5auvs3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/rm5auvs3' target=\"_blank\">celestial-feather-25</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/rm5auvs3' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/rm5auvs3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Dataset Selection\n",
        "dataset_name = \"PASCAL-VOC2007\"  # Choose from [\"NUS-WIDE\", \"MS-COCO\", \"PASCAL-VOC2007\", \"VOC2012\", \"Visual Genome\", \"News-500\", \"CUB\"]\n",
        "\n",
        "# Define Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define MultiLabelBinarizer\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])  # Fix NotFittedError\n",
        "\n",
        "# Custom Dataset Class\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, root, dataset_name, transform=None):\n",
        "        if dataset_name == \"VOC2012\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2012\", image_set=\"train\", download=True)\n",
        "        elif dataset_name == \"PASCAL-VOC2007\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2007\", image_set=\"train\", download=True)\n",
        "        else:\n",
        "            raise ValueError(\"Dataset not supported yet!\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        labels = [obj[\"name\"] for obj in target[\"annotation\"][\"object\"]]\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = MultiLabelDataset(root=\"./data\", dataset_name=dataset_name, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define Model Options\n",
        "model_choices = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"mobilenet_v2\": models.mobilenet_v2,\n",
        "    \"vgg16\": models.vgg16,\n",
        "    \"densenet121\": models.densenet121,\n",
        "    \"alexnet\": models.alexnet,\n",
        "    \"googlenet\": models.googlenet\n",
        "}\n",
        "model_name = \"googlenet\"  # Choose model\n",
        "\n",
        "# Define Multi-Label Classification Model\n",
        "class MultiLabelModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=20, dropout_rate=0.5):\n",
        "        super(MultiLabelModel, self).__init__()\n",
        "        self.model = model_choices[model_name](pretrained=True)\n",
        "        if \"fc\" in dir(self.model):\n",
        "            in_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            in_features = self.model.classifier[6].in_features\n",
        "            self.model.classifier[6] = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.model(x))\n",
        "\n",
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiLabelModel(model_name=model_name, num_classes=20, dropout_rate=0.3).to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "train_losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        predictions = (outputs > 0.5).float()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "    avg_loss = running_loss / len(train_dataloader)\n",
        "    accuracy = accuracy_score(np.array(y_true), np.array(y_pred))\n",
        "    train_losses.append(avg_loss)\n",
        "    accuracies.append(accuracy)\n",
        "    wandb.log({\"Loss\": avg_loss, \"Accuracy\": accuracy})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Plot Loss and Accuracy Curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, marker='o', linestyle='-', color='b', label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), accuracies, marker='s', linestyle='-', color='r', label='Training Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metrics\")\n",
        "plt.title(\"Training Loss and Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgQ2z27bKm-"
      },
      "source": [
        "NUS WIDE dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ffSZlvZtIa",
        "outputId": "b3b626eb-b011-4cd5-db5b-06c0fa300437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xinleili/nuswide?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.77G/5.77G [00:55<00:00, 113MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/xinleili/nuswide/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"xinleili/nuswide\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "Qfg-59HOeg8d",
        "outputId": "9c663549-7648-4539-dace-21e77bc3d27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV files not found. Creating train.csv and val.csv from dataset images...\n",
            "Created 215723 training samples and 53931 validation samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250310_090810-nl7g8moi</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/nl7g8moi' target=\"_blank\">hl_3_bs_16_ac_ReLU</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/nl7g8moi' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/nl7g8moi</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 120MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 4.0295, Val Loss: 0.6415, Exact Match: 0.0006, Hamming Loss: 0.3334\n",
            "Epoch 2/10, Train Loss: 4.0083, Val Loss: 0.6447, Exact Match: 0.0004, Hamming Loss: 0.3333\n",
            "Epoch 3/10, Train Loss: 4.0035, Val Loss: 0.6406, Exact Match: 0.0002, Hamming Loss: 0.3332\n",
            "Epoch 4/10, Train Loss: 3.9991, Val Loss: 0.6412, Exact Match: 0.0000, Hamming Loss: 0.3329\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import wandb\n",
        "\n",
        "##############################################\n",
        "# Function to create train.csv and val.csv by scanning the dataset_dir recursively.\n",
        "##############################################\n",
        "def create_csv_files(dataset_dir, train_csv_path, val_csv_path, classes, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Recursively scans the dataset_dir for image files,\n",
        "    generates random multi-label annotations (for demo purposes), and splits them into\n",
        "    training and validation CSV files.\n",
        "    \"\"\"\n",
        "    # Use recursive globbing to find images in all subdirectories.\n",
        "    img_extensions = (\"*.jpg\", \"*.jpeg\", \"*.png\")\n",
        "    image_files = []\n",
        "    for ext in img_extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(dataset_dir, \"**\", ext), recursive=True))\n",
        "    image_files = sorted(image_files)\n",
        "\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(f\"No image files found in {dataset_dir} (searched recursively)\")\n",
        "\n",
        "    # Generate a random multi-label for each image.\n",
        "    # For demonstration, assign each image between 1 and 3 random labels.\n",
        "    data = []\n",
        "    for img_path in image_files:\n",
        "        num_labels = random.randint(1, min(3, len(classes)))\n",
        "        labels = random.sample(classes, num_labels)\n",
        "        labels_str = \",\".join(labels)\n",
        "        data.append({\"image_path\": img_path, \"labels\": labels_str})\n",
        "\n",
        "    # Shuffle and split data.\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * train_ratio)\n",
        "    train_data = data[:split_idx]\n",
        "    val_data = data[split_idx:]\n",
        "\n",
        "    # Save to CSV.\n",
        "    pd.DataFrame(train_data).to_csv(train_csv_path, index=False)\n",
        "    pd.DataFrame(val_data).to_csv(val_csv_path, index=False)\n",
        "    print(f\"Created {len(train_data)} training samples and {len(val_data)} validation samples.\")\n",
        "\n",
        "##############################################\n",
        "# Custom Dataset for Multi-label Classification\n",
        "##############################################\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, classes, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (str): Path to the CSV file with annotations.\n",
        "            classes (list): List of all possible class names.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        labels_str = row['labels']  # Expected format: \"cat,dog,bird\", etc.\n",
        "        labels_list = labels_str.split(',')\n",
        "        # Create a multi-hot vector.\n",
        "        label_vector = np.zeros(len(self.classes), dtype=np.float32)\n",
        "        for label in labels_list:\n",
        "            label = label.strip()\n",
        "            if label in self.classes:\n",
        "                label_vector[self.classes.index(label)] = 1.0\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label_vector)\n",
        "\n",
        "##############################################\n",
        "# Multi-label Model based on ResNet50\n",
        "##############################################\n",
        "class MultiLabelResNet(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0.5):\n",
        "        super(MultiLabelResNet, self).__init__()\n",
        "        self.base_model = models.resnet50(pretrained=True)\n",
        "        num_ftrs = self.base_model.fc.in_features\n",
        "        self.base_model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "##############################################\n",
        "# Ranking Loss for Multi-label Learning\n",
        "##############################################\n",
        "class RankingLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(RankingLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0.0\n",
        "        batch_size = outputs.size(0)\n",
        "        for i in range(batch_size):\n",
        "            pos_idx = (targets[i] == 1).nonzero(as_tuple=False).squeeze()\n",
        "            neg_idx = (targets[i] == 0).nonzero(as_tuple=False).squeeze()\n",
        "            if pos_idx.dim() == 0:\n",
        "                pos_idx = pos_idx.unsqueeze(0)\n",
        "            if neg_idx.dim() == 0:\n",
        "                neg_idx = neg_idx.unsqueeze(0)\n",
        "            pos_scores = outputs[i][pos_idx]\n",
        "            neg_scores = outputs[i][neg_idx]\n",
        "            for pos in pos_scores:\n",
        "                for neg in neg_scores:\n",
        "                    loss += torch.clamp(self.margin - (pos - neg), min=0)\n",
        "        return loss / batch_size\n",
        "\n",
        "##############################################\n",
        "# Combined Loss: Ranking Loss + BCE Loss\n",
        "##############################################\n",
        "def combined_loss(outputs, targets, ranking_loss_fn, bce_loss_fn, alpha=0.5):\n",
        "    loss_ranking = ranking_loss_fn(outputs, targets)\n",
        "    loss_bce = bce_loss_fn(outputs, targets)\n",
        "    return alpha * loss_ranking + (1 - alpha) * loss_bce\n",
        "\n",
        "##############################################\n",
        "# Validation Function to Compute Metrics\n",
        "##############################################\n",
        "def validate(model, val_loader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    exact_match = 0\n",
        "    hamming_loss_total = 0.0\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = bce_loss_fn(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds = (preds > threshold).float()\n",
        "            exact_match += (preds == labels).all(dim=1).sum().item()\n",
        "            sample_hamming = (preds != labels).sum(dim=1) / labels.size(1)\n",
        "            hamming_loss_total += sample_hamming.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    exact_match_ratio = exact_match / total_samples\n",
        "    avg_hamming_loss = hamming_loss_total / total_samples\n",
        "    return avg_loss, exact_match_ratio, avg_hamming_loss\n",
        "\n",
        "##############################################\n",
        "# Main Training and Evaluation Loop\n",
        "##############################################\n",
        "def main():\n",
        "    # Define the dataset directory for NUSWIDE.\n",
        "    dataset_dir = \"/root/.cache/kagglehub/datasets/xinleili/nuswide/versions/1\"\n",
        "    csv_train_path = os.path.join(dataset_dir, \"train.csv\")\n",
        "    csv_val_path   = os.path.join(dataset_dir, \"val.csv\")\n",
        "\n",
        "    # Define the classes (for simulation/demo purposes).\n",
        "    classes = [\"cat\", \"dog\", \"bird\", \"fruit\", \"vegetable\", \"flower\"]\n",
        "\n",
        "    # Create CSV files if they do not exist.\n",
        "    if not os.path.exists(csv_train_path) or not os.path.exists(csv_val_path):\n",
        "        print(\"CSV files not found. Creating train.csv and val.csv from dataset images...\")\n",
        "        create_csv_files(dataset_dir, csv_train_path, csv_val_path, classes, train_ratio=0.8)\n",
        "\n",
        "    # Configuration parameters.\n",
        "    config_dict = {\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": \"ResNet50\",\n",
        "        \"hidden_layers\": 3,          # For naming only.\n",
        "        \"activation\": \"ReLU\",        # For naming only.\n",
        "        \"data_augmentation\": \"Resize+RandomHorizontalFlip\",\n",
        "        \"dropout_rate\": 0.5,\n",
        "        \"image_size\": 224,\n",
        "        \"loss_alpha\": 0.5,           # Weight for ranking loss vs. BCE loss.\n",
        "        \"csv_train\": csv_train_path,\n",
        "        \"csv_val\": csv_val_path,\n",
        "        \"classes\": classes\n",
        "    }\n",
        "\n",
        "    # Build a descriptive run name.\n",
        "    run_name = f\"hl_{config_dict['hidden_layers']}_bs_{config_dict['batch_size']}_ac_{config_dict['activation']}\"\n",
        "\n",
        "    # Initialize wandb.\n",
        "    wandb.init(project=\"multi_label_classification\", name=run_name, config=config_dict)\n",
        "    config = wandb.config\n",
        "\n",
        "    # Data transformations.\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets.\n",
        "    train_dataset = MultiLabelDataset(csv_file=config.csv_train, classes=config.classes, transform=train_transforms)\n",
        "    val_dataset   = MultiLabelDataset(csv_file=config.csv_val, classes=config.classes, transform=val_transforms)\n",
        "\n",
        "    # Data loaders.\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_classes = len(config.classes)\n",
        "\n",
        "    # Initialize model.\n",
        "    model = MultiLabelResNet(num_classes, dropout_rate=config.dropout_rate).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    ranking_loss_fn = RankingLoss(margin=1.0)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    epochs_list = []\n",
        "\n",
        "    # Training loop.\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = combined_loss(outputs, labels, ranking_loss_fn, bce_loss_fn, alpha=config.loss_alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_dataset)\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch})\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "\n",
        "        # Validation.\n",
        "        val_loss, exact_match_ratio, avg_hamming_loss = validate(model, val_loader, device)\n",
        "        wandb.log({\n",
        "            \"val_loss\": val_loss,\n",
        "            \"exact_match_ratio\": exact_match_ratio,\n",
        "            \"avg_hamming_loss\": avg_hamming_loss,\n",
        "            \"epoch\": epoch\n",
        "        })\n",
        "        val_loss_list.append(val_loss)\n",
        "        epochs_list.append(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Exact Match: {exact_match_ratio:.4f}, Hamming Loss: {avg_hamming_loss:.4f}\")\n",
        "\n",
        "    # Plot and log loss curves.\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
        "    plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "    plt.show()\n",
        "\n",
        "    # Save the model.\n",
        "    torch.save(model.state_dict(), \"multi_label_resnet.pth\")\n",
        "    wandb.save(\"multi_label_resnet.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUS WIDE with ALEXNET"
      ],
      "metadata": {
        "id": "SwyU6uUtB_-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nTeHb9HhXtEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3479871b-2d04-4f07-c9a0-d5aaa26ab7be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xinleili/nuswide?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.77G/5.77G [01:29<00:00, 69.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/xinleili/nuswide/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"xinleili/nuswide\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4wz9jlRoXx0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "294d5c82-a0fb-4746-82ad-e3b56e29d737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files not found. Creating train.csv and val.csv from dataset images...\n",
            "Created 215723 training samples and 53931 validation samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250315_090154-8sfsm7r2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/8sfsm7r2' target=\"_blank\">hl_3_bs_16_ac_ReLU</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/8sfsm7r2' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/8sfsm7r2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 172MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 3.9940, Val Loss: 0.6443, Exact Match: 0.0000, Hamming Loss: 0.3338\n",
            "Epoch 2/3, Train Loss: 3.9878, Val Loss: 0.6434, Exact Match: 0.0000, Hamming Loss: 0.3338\n",
            "Epoch 3/3, Train Loss: 3.9895, Val Loss: 0.6398, Exact Match: 0.0000, Hamming Loss: 0.3338\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import wandb\n",
        "\n",
        "##############################################\n",
        "# Function to create train.csv and val.csv by scanning the dataset_dir recursively.\n",
        "##############################################\n",
        "def create_csv_files(dataset_dir, train_csv_path, val_csv_path, classes, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Recursively scans the dataset_dir for image files,\n",
        "    generates random multi-label annotations (for demo purposes), and splits them into\n",
        "    training and validation CSV files.\n",
        "    \"\"\"\n",
        "    # Use recursive globbing to find images in all subdirectories.\n",
        "    img_extensions = (\"*.jpg\", \"*.jpeg\", \"*.png\")\n",
        "    image_files = []\n",
        "    for ext in img_extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(dataset_dir, \"**\", ext), recursive=True))\n",
        "    image_files = sorted(image_files)\n",
        "\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(f\"No image files found in {dataset_dir} (searched recursively)\")\n",
        "\n",
        "    # Generate a random multi-label for each image.\n",
        "    # For demonstration, assign each image between 1 and 3 random labels.\n",
        "    data = []\n",
        "    for img_path in image_files:\n",
        "        num_labels = random.randint(1, min(3, len(classes)))\n",
        "        labels = random.sample(classes, num_labels)\n",
        "        labels_str = \",\".join(labels)\n",
        "        data.append({\"image_path\": img_path, \"labels\": labels_str})\n",
        "\n",
        "    # Shuffle and split data.\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * train_ratio)\n",
        "    train_data = data[:split_idx]\n",
        "    val_data = data[split_idx:]\n",
        "\n",
        "    # Save to CSV.\n",
        "    pd.DataFrame(train_data).to_csv(train_csv_path, index=False)\n",
        "    pd.DataFrame(val_data).to_csv(val_csv_path, index=False)\n",
        "    print(f\"Created {len(train_data)} training samples and {len(val_data)} validation samples.\")\n",
        "\n",
        "##############################################\n",
        "# Custom Dataset for Multi-label Classification\n",
        "##############################################\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, classes, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (str): Path to the CSV file with annotations.\n",
        "            classes (list): List of all possible class names.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        labels_str = row['labels']  # Expected format: \"cat,dog,bird\", etc.\n",
        "        labels_list = labels_str.split(',')\n",
        "        # Create a multi-hot vector.\n",
        "        label_vector = np.zeros(len(self.classes), dtype=np.float32)\n",
        "        for label in labels_list:\n",
        "            label = label.strip()\n",
        "            if label in self.classes:\n",
        "                label_vector[self.classes.index(label)] = 1.0\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label_vector)\n",
        "\n",
        "##############################################\n",
        "# Multi-label Model based on ResNet50\n",
        "##############################################\n",
        "class MultiLabelAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0.5):\n",
        "        super(MultiLabelAlexNet, self).__init__()\n",
        "        self.base_model = models.alexnet(pretrained=True)\n",
        "        num_ftrs = self.base_model.classifier[6].in_features  # AlexNet's last FC layer input size\n",
        "        self.base_model.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "##############################################\n",
        "# Ranking Loss for Multi-label Learning\n",
        "##############################################\n",
        "class RankingLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(RankingLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0.0\n",
        "        batch_size = outputs.size(0)\n",
        "        for i in range(batch_size):\n",
        "            pos_idx = (targets[i] == 1).nonzero(as_tuple=False).squeeze()\n",
        "            neg_idx = (targets[i] == 0).nonzero(as_tuple=False).squeeze()\n",
        "            if pos_idx.dim() == 0:\n",
        "                pos_idx = pos_idx.unsqueeze(0)\n",
        "            if neg_idx.dim() == 0:\n",
        "                neg_idx = neg_idx.unsqueeze(0)\n",
        "            pos_scores = outputs[i][pos_idx]\n",
        "            neg_scores = outputs[i][neg_idx]\n",
        "            for pos in pos_scores:\n",
        "                for neg in neg_scores:\n",
        "                    loss += torch.clamp(self.margin - (pos - neg), min=0)\n",
        "        return loss / batch_size\n",
        "\n",
        "##############################################\n",
        "# Combined Loss: Ranking Loss + BCE Loss\n",
        "##############################################\n",
        "def combined_loss(outputs, targets, ranking_loss_fn, bce_loss_fn, alpha=0.5):\n",
        "    loss_ranking = ranking_loss_fn(outputs, targets)\n",
        "    loss_bce = bce_loss_fn(outputs, targets)\n",
        "    return alpha * loss_ranking + (1 - alpha) * loss_bce\n",
        "\n",
        "##############################################\n",
        "# Validation Function to Compute Metrics\n",
        "##############################################\n",
        "def validate(model, val_loader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    exact_match = 0\n",
        "    hamming_loss_total = 0.0\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = bce_loss_fn(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds = (preds > threshold).float()\n",
        "            exact_match += (preds == labels).all(dim=1).sum().item()\n",
        "            sample_hamming = (preds != labels).sum(dim=1) / labels.size(1)\n",
        "            hamming_loss_total += sample_hamming.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    exact_match_ratio = exact_match / total_samples\n",
        "    avg_hamming_loss = hamming_loss_total / total_samples\n",
        "    return avg_loss, exact_match_ratio, avg_hamming_loss\n",
        "\n",
        "##############################################\n",
        "# Main Training and Evaluation Loop\n",
        "##############################################\n",
        "def main():\n",
        "    # Define the dataset directory for NUSWIDE.\n",
        "    dataset_dir = \"/root/.cache/kagglehub/datasets/xinleili/nuswide/versions/1\"\n",
        "    csv_train_path = os.path.join(dataset_dir, \"train.csv\")\n",
        "    csv_val_path   = os.path.join(dataset_dir, \"val.csv\")\n",
        "\n",
        "    # Define the classes (for simulation/demo purposes).\n",
        "    classes = [\"cat\", \"dog\", \"bird\", \"fruit\", \"vegetable\", \"flower\"]\n",
        "\n",
        "    # Create CSV files if they do not exist.\n",
        "    if not os.path.exists(csv_train_path) or not os.path.exists(csv_val_path):\n",
        "        print(\"CSV files not found. Creating train.csv and val.csv from dataset images...\")\n",
        "        create_csv_files(dataset_dir, csv_train_path, csv_val_path, classes, train_ratio=0.8)\n",
        "\n",
        "    # Configuration parameters.\n",
        "    config_dict = {\n",
        "        \"epochs\": 3,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": \"AlexNet\",\n",
        "        \"hidden_layers\": 3,          # For naming only.\n",
        "        \"activation\": \"ReLU\",        # For naming only.\n",
        "        \"data_augmentation\": \"Resize+RandomHorizontalFlip\",\n",
        "        \"dropout_rate\": 0.5,\n",
        "        \"image_size\": 224,\n",
        "        \"loss_alpha\": 0.5,           # Weight for ranking loss vs. BCE loss.\n",
        "        \"csv_train\": csv_train_path,\n",
        "        \"csv_val\": csv_val_path,\n",
        "        \"classes\": classes\n",
        "    }\n",
        "\n",
        "    # Build a descriptive run name.\n",
        "    run_name = f\"hl_{config_dict['hidden_layers']}_bs_{config_dict['batch_size']}_ac_{config_dict['activation']}\"\n",
        "\n",
        "    # Initialize wandb.\n",
        "    wandb.init(project=\"multi_label_classification\", name=run_name, config=config_dict)\n",
        "    config = wandb.config\n",
        "\n",
        "    # Data transformations.\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets.\n",
        "    train_dataset = MultiLabelDataset(csv_file=config.csv_train, classes=config.classes, transform=train_transforms)\n",
        "    val_dataset   = MultiLabelDataset(csv_file=config.csv_val, classes=config.classes, transform=val_transforms)\n",
        "\n",
        "    # Data loaders.\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_classes = len(config.classes)\n",
        "\n",
        "    # Initialize model.\n",
        "    model = MultiLabelAlexNet(num_classes, dropout_rate=config.dropout_rate).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    ranking_loss_fn = RankingLoss(margin=1.0)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    epochs_list = []\n",
        "\n",
        "    # Training loop.\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = combined_loss(outputs, labels, ranking_loss_fn, bce_loss_fn, alpha=config.loss_alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_dataset)\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch})\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "\n",
        "        # Validation.\n",
        "        val_loss, exact_match_ratio, avg_hamming_loss = validate(model, val_loader, device)\n",
        "        wandb.log({\n",
        "            \"val_loss\": val_loss,\n",
        "            \"exact_match_ratio\": exact_match_ratio,\n",
        "            \"avg_hamming_loss\": avg_hamming_loss,\n",
        "            \"epoch\": epoch\n",
        "        })\n",
        "        val_loss_list.append(val_loss)\n",
        "        epochs_list.append(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Exact Match: {exact_match_ratio:.4f}, Hamming Loss: {avg_hamming_loss:.4f}\")\n",
        "\n",
        "    # Plot and log loss curves.\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
        "    plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "    plt.show()\n",
        "\n",
        "    # Save the model.\n",
        "    torch.save(model.state_dict(), \"multi_label_resnet.pth\")\n",
        "    wandb.save(\"multi_label_resnet.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3uV5NTiklD1"
      },
      "source": [
        "Visual Genome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8tXYSQNin-_",
        "outputId": "34f5c9aa-d7f4-48dd-b2ab-d08afe988a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mathurinache/visual-genome?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 129M/129M [00:03<00:00, 37.5MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mathurinache/visual-genome/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mathurinache/visual-genome\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6v6RVFjJoc",
        "outputId": "1400eb85-cd12-45fd-f4ef-b73d226e0435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attribute_synsets.json  objects.json         relationship_alias.txt  relationship_synsets.json\n",
            "object_alias.txt        object_synsets.json  relationships.json      \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "sffSZgzcjCzT",
        "outputId": "1b06327d-3571-4b77-fc0f-57a91fde2be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV files not found. Creating train.csv and val.csv from Visual Genome objects...\n",
            "Warning: No images found in /root/.cache/kagglehub/datasets/mathurinache/visual-genome/versions/1. Dummy images will be used.\n",
            "Created 82968 training samples and 20743 validation samples for Visual Genome.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250314_184240-ta60t36c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/ta60t36c' target=\"_blank\">hl_3_bs_16_ac_ReLU</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/ta60t36c' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/ta60t36c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 87.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import wandb\n",
        "\n",
        "##############################################\n",
        "# Helper function to find a file recursively in a directory.\n",
        "##############################################\n",
        "def find_file(filename, directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "##############################################\n",
        "# Helper function to fix image paths.\n",
        "##############################################\n",
        "def fix_image_path(rel_path, base_dir):\n",
        "    path = os.path.join(base_dir, rel_path)\n",
        "    if os.path.exists(path):\n",
        "        return path\n",
        "    alt_path = os.path.join(base_dir, \"images\", rel_path)\n",
        "    if os.path.exists(alt_path):\n",
        "        return alt_path\n",
        "    return path\n",
        "\n",
        "##############################################\n",
        "# Build a mapping from image ID to image file path.\n",
        "##############################################\n",
        "def build_image_dict(dataset_dir):\n",
        "    # Try \"images\" subfolder first; if not present, use dataset_dir.\n",
        "    images_folder = os.path.join(dataset_dir, \"images\")\n",
        "    if not os.path.exists(images_folder):\n",
        "        images_folder = dataset_dir\n",
        "    # Search common image extensions.\n",
        "    image_files = glob.glob(os.path.join(images_folder, \"*.jpg\")) + \\\n",
        "                  glob.glob(os.path.join(images_folder, \"*.jpeg\")) + \\\n",
        "                  glob.glob(os.path.join(images_folder, \"*.png\"))\n",
        "    image_dict = {}\n",
        "    for path in image_files:\n",
        "        basename = os.path.basename(path)\n",
        "        img_id = os.path.splitext(basename)[0]\n",
        "        image_dict[img_id] = path\n",
        "    if not image_dict:\n",
        "        print(f\"Warning: No images found in {images_folder}. Dummy images will be used.\")\n",
        "    return image_dict\n",
        "\n",
        "##############################################\n",
        "# Function to create a dummy image and return its path.\n",
        "##############################################\n",
        "def get_dummy_image(dataset_dir, size=(224,224), color=(0,0,0)):\n",
        "    dummy_path = os.path.join(dataset_dir, \"dummy.jpg\")\n",
        "    if not os.path.exists(dummy_path):\n",
        "        dummy_img = Image.new(\"RGB\", size, color)\n",
        "        dummy_img.save(dummy_path)\n",
        "    return dummy_path\n",
        "\n",
        "##############################################\n",
        "# Function to create train.csv and val.csv for Visual Genome using objects.json.\n",
        "##############################################\n",
        "def create_csv_files_vg(dataset_dir, train_csv_path, val_csv_path, train_ratio=0.8, top_k=50):\n",
        "    \"\"\"\n",
        "    Reads object annotations from objects.json (from Visual Genome v1.4)\n",
        "    and creates train.csv and val.csv for multi-label classification.\n",
        "\n",
        "    It uses the annotation file objects.json and, if available, object_alias.txt to map synonyms.\n",
        "    Then, it counts the frequency of object names, retains only the top_k most frequent,\n",
        "    filters each image’s label set accordingly, shuffles, and splits into train/val CSV files.\n",
        "\n",
        "    If image files are not found, a dummy image is used.\n",
        "    \"\"\"\n",
        "    # Locate the objects annotation file.\n",
        "    objects_file = find_file(\"objects.json\", dataset_dir)\n",
        "    if not objects_file:\n",
        "        raise FileNotFoundError(\"objects.json not found in the dataset directory.\")\n",
        "\n",
        "    with open(objects_file, 'r') as f:\n",
        "        objects_data = json.load(f)\n",
        "\n",
        "    # Build a mapping from image ID to image file path.\n",
        "    image_dict = build_image_dict(dataset_dir)\n",
        "\n",
        "    # Read alias mapping from object_alias.txt if available.\n",
        "    alias_file = find_file(\"object_alias.txt\", dataset_dir)\n",
        "    alias_mapping = {}\n",
        "    if alias_file:\n",
        "        with open(alias_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                synonyms = line.strip().split(\",\")\n",
        "                if synonyms:\n",
        "                    canonical = synonyms[0].strip().lower()\n",
        "                    for syn in synonyms:\n",
        "                        alias_mapping[syn.strip().lower()] = canonical\n",
        "\n",
        "    freq = {}\n",
        "    rows = []\n",
        "    # Process each annotation entry.\n",
        "    for entry in objects_data:\n",
        "        image_id = str(entry.get(\"image_id\"))\n",
        "        obj_list = entry.get(\"objects\", [])\n",
        "        labels_set = set()\n",
        "        for obj in obj_list:\n",
        "            names = obj.get(\"names\", [])\n",
        "            for name in names:\n",
        "                name = name.lower().strip()\n",
        "                if name in alias_mapping:\n",
        "                    name = alias_mapping[name]\n",
        "                labels_set.add(name)\n",
        "                freq[name] = freq.get(name, 0) + 1\n",
        "        # Even if no labels, add the row (it may later be filtered).\n",
        "        label_str = \",\".join(sorted(labels_set))\n",
        "        if image_id in image_dict:\n",
        "            image_path = image_dict[image_id]\n",
        "        else:\n",
        "            image_path = get_dummy_image(dataset_dir)\n",
        "        rows.append({\"image_path\": image_path, \"labels\": label_str})\n",
        "\n",
        "    if not rows:\n",
        "        raise FileNotFoundError(\"No annotation rows could be generated from objects.json.\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    # Determine top_k most frequent labels.\n",
        "    sorted_classes = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_classes = set([cls for cls, count in sorted_classes[:top_k]])\n",
        "\n",
        "    def filter_labels(label_str):\n",
        "        labels = label_str.split(\",\")\n",
        "        filtered = [l for l in labels if l in top_classes]\n",
        "        return \",\".join(sorted(filtered))\n",
        "\n",
        "    df[\"labels\"] = df[\"labels\"].apply(filter_labels)\n",
        "    # Remove rows with empty label set.\n",
        "    df = df[df[\"labels\"] != \"\"]\n",
        "\n",
        "    # Final list of classes used.\n",
        "    classes = sorted(set(\",\".join(df[\"labels\"].tolist()).split(\",\")))\n",
        "\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    split_idx = int(len(df) * train_ratio)\n",
        "    train_df = df.iloc[:split_idx]\n",
        "    val_df = df.iloc[split_idx:]\n",
        "\n",
        "    train_df.to_csv(train_csv_path, index=False)\n",
        "    val_df.to_csv(val_csv_path, index=False)\n",
        "    print(f\"Created {len(train_df)} training samples and {len(val_df)} validation samples for Visual Genome.\")\n",
        "\n",
        "    return classes\n",
        "\n",
        "##############################################\n",
        "# Custom Dataset for Multi-label Classification\n",
        "##############################################\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, classes, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        label_str = row['labels'].strip()\n",
        "        label_vector = np.zeros(len(self.classes), dtype=np.float32)\n",
        "        for label in label_str.split(\",\"):\n",
        "            if label in self.classes:\n",
        "                label_vector[self.classes.index(label)] = 1.0\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label_vector)\n",
        "\n",
        "##############################################\n",
        "# Multi-label Model based on ResNet50\n",
        "##############################################\n",
        "class MultiLabelResNet(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0.5):\n",
        "        super(MultiLabelResNet, self).__init__()\n",
        "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.base_model.fc.in_features\n",
        "        self.base_model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "##############################################\n",
        "# Ranking Loss for Multi-label Learning\n",
        "##############################################\n",
        "class RankingLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(RankingLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0.0\n",
        "        batch_size = outputs.size(0)\n",
        "        for i in range(batch_size):\n",
        "            pos_idx = (targets[i] == 1).nonzero(as_tuple=False).squeeze()\n",
        "            neg_idx = (targets[i] == 0).nonzero(as_tuple=False).squeeze()\n",
        "            if pos_idx.dim() == 0:\n",
        "                pos_idx = pos_idx.unsqueeze(0)\n",
        "            if neg_idx.dim() == 0:\n",
        "                neg_idx = neg_idx.unsqueeze(0)\n",
        "            pos_scores = outputs[i][pos_idx]\n",
        "            neg_scores = outputs[i][neg_idx]\n",
        "            for pos in pos_scores:\n",
        "                for neg in neg_scores:\n",
        "                    loss += torch.clamp(self.margin - (pos - neg), min=0)\n",
        "        return loss / batch_size\n",
        "\n",
        "##############################################\n",
        "# Combined Loss: Ranking Loss + BCE Loss\n",
        "##############################################\n",
        "def combined_loss(outputs, targets, ranking_loss_fn, bce_loss_fn, alpha=0.5):\n",
        "    loss_ranking = ranking_loss_fn(outputs, targets)\n",
        "    loss_bce = bce_loss_fn(outputs, targets)\n",
        "    return alpha * loss_ranking + (1 - alpha) * loss_bce\n",
        "\n",
        "##############################################\n",
        "# Validation Function to Compute Metrics\n",
        "##############################################\n",
        "def validate(model, val_loader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    exact_match = 0\n",
        "    hamming_loss_total = 0.0\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = bce_loss_fn(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds = (preds > threshold).float()\n",
        "            exact_match += (preds == labels).all(dim=1).sum().item()\n",
        "            sample_hamming = (preds != labels).sum(dim=1) / labels.size(1)\n",
        "            hamming_loss_total += sample_hamming.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    exact_match_ratio = exact_match / total_samples\n",
        "    avg_hamming_loss = hamming_loss_total / total_samples\n",
        "    return avg_loss, exact_match_ratio, avg_hamming_loss\n",
        "\n",
        "##############################################\n",
        "# Main Training and Evaluation Loop\n",
        "##############################################\n",
        "def main():\n",
        "    # Set dataset_dir to your Visual Genome dataset directory.\n",
        "    dataset_dir = \"/root/.cache/kagglehub/datasets/mathurinache/visual-genome/versions/1\"\n",
        "    csv_train_path = os.path.join(dataset_dir, \"train.csv\")\n",
        "    csv_val_path = os.path.join(dataset_dir, \"val.csv\")\n",
        "\n",
        "    if not os.path.exists(csv_train_path) or not os.path.exists(csv_val_path):\n",
        "        print(\"CSV files not found. Creating train.csv and val.csv from Visual Genome objects...\")\n",
        "        classes = create_csv_files_vg(dataset_dir, csv_train_path, csv_val_path, train_ratio=0.8, top_k=50)\n",
        "    else:\n",
        "        df = pd.read_csv(csv_train_path)\n",
        "        classes = sorted(set(\",\".join(df[\"labels\"].tolist()).split(\",\")))\n",
        "\n",
        "    config_dict = {\n",
        "        \"epochs\": 3,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": \"ResNet50\",\n",
        "        \"hidden_layers\": 3,\n",
        "        \"activation\": \"ReLU\",\n",
        "        \"data_augmentation\": \"Resize+RandomHorizontalFlip\",\n",
        "        \"dropout_rate\": 0.5,\n",
        "        \"image_size\": 224,\n",
        "        \"loss_alpha\": 0.5,\n",
        "        \"csv_train\": csv_train_path,\n",
        "        \"csv_val\": csv_val_path,\n",
        "        \"classes\": classes\n",
        "    }\n",
        "\n",
        "    run_name = f\"hl_{config_dict['hidden_layers']}_bs_{config_dict['batch_size']}_ac_{config_dict['activation']}\"\n",
        "    wandb.init(project=\"multi_label_classification\", name=run_name, config=config_dict)\n",
        "    config = wandb.config\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = MultiLabelDataset(csv_file=config.csv_train, classes=config.classes, transform=train_transforms)\n",
        "    val_dataset = MultiLabelDataset(csv_file=config.csv_val, classes=config.classes, transform=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_classes = len(config.classes)\n",
        "\n",
        "    model = MultiLabelResNet(num_classes, dropout_rate=config.dropout_rate).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    ranking_loss_fn = RankingLoss(margin=1.0)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    epochs_list = []\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = combined_loss(outputs, labels, ranking_loss_fn, bce_loss_fn, alpha=config.loss_alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_dataset)\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch})\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "\n",
        "        val_loss, exact_match_ratio, avg_hamming_loss = validate(model, val_loader, device)\n",
        "        wandb.log({\n",
        "            \"val_loss\": val_loss,\n",
        "            \"exact_match_ratio\": exact_match_ratio,\n",
        "            \"avg_hamming_loss\": avg_hamming_loss,\n",
        "            \"epoch\": epoch\n",
        "        })\n",
        "        val_loss_list.append(val_loss)\n",
        "        epochs_list.append(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Exact Match: {exact_match_ratio:.4f}, Hamming Loss: {avg_hamming_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
        "    plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "    plt.show()\n",
        "\n",
        "    torch.save(model.state_dict(), \"multi_label_resnet.pth\")\n",
        "    wandb.save(\"multi_label_resnet.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfBbpI/vxzJx7CvhzxfGqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}