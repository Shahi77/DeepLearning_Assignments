{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahi77/DeepLearning_Assignments/blob/main/Assignment05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VOC2012"
      ],
      "metadata": {
        "id": "7pkG6AxgjBNO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZWM-ULLmiH8",
        "outputId": "0f575c2d-061f-49ef-d267-d78621342b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.2202\n",
            "Epoch 2/5, Loss: 0.1943\n",
            "Epoch 3/5, Loss: 0.1806\n",
            "Epoch 4/5, Loss: 0.1681\n",
            "Epoch 5/5, Loss: 0.1557\n",
            "Accuracy: 0.3215, Hamming Loss: 0.0523, Precision: 0.7502, Recall: 0.4324, F1-score: 0.4668, Jaccard Index: 0.3433\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Define VOC 2012 class labels (20 classes)\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "# Initialize and fit MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])  # Fit with all possible classes\n",
        "\n",
        "# Define Data Augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset Wrapper for Multi-Label Classification\n",
        "class VOCMultiLabelDataset(Dataset):\n",
        "    def __init__(self, root=\"./data\", year=\"2012\", image_set=\"train\", transform=None):\n",
        "        self.dataset = datasets.VOCDetection(root=root, year=year, image_set=image_set, download=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        objects = target[\"annotation\"][\"object\"]\n",
        "\n",
        "        # If only one object exists, wrap it in a list\n",
        "        if isinstance(objects, dict):\n",
        "            objects = [objects]\n",
        "\n",
        "        labels = [obj[\"name\"] for obj in objects]\n",
        "\n",
        "        # Convert labels to one-hot encoding\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Load Datasets\n",
        "train_dataset = VOCMultiLabelDataset(transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)# Set num_workers=0 for Colab\n",
        "\n",
        "# Define Multi-Label Classification Model\n",
        "class MultiLabelResNet(nn.Module):\n",
        "    def __init__(self, num_classes=20):\n",
        "        super(MultiLabelResNet, self).__init__()\n",
        "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Correct way to load pretrained model\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()  # For multi-label classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.model(x))\n",
        "\n",
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiLabelResNet(num_classes=20).to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    wandb.log({\"Loss\": running_loss / len(train_dataloader)})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "h_loss = hamming_loss(y_true, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "jaccard = jaccard_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Log to wandb\n",
        "wandb.log({\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Hamming Loss\": h_loss,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1-score\": f1,\n",
        "    \"Jaccard Index\": jaccard\n",
        "})\n",
        "\n",
        "# Print Metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}, Hamming Loss: {h_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Jaccard Index: {jaccard:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_4gNuFtR17J",
        "outputId": "5c1291e2-92cf-4a35-af7c-87933a4b8281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
            "Epoch 1/5, Loss: 0.1672\n",
            "Epoch 2/5, Loss: 0.1372\n",
            "Epoch 3/5, Loss: 0.1286\n",
            "Epoch 4/5, Loss: 0.1191\n",
            "Epoch 5/5, Loss: 0.1125\n",
            "Model: MobileNetV2, Dropout: 0.3, Augmentation: strong, Image Size: 224\n",
            "Accuracy: 0.5403, Hamming Loss: 0.0332, Precision: 0.8530, Recall: 0.6556, F1-score: 0.7273, Jaccard Index: 0.5859\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Define VOC 2012 class labels (20 classes)\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])\n",
        "\n",
        "# Define Multiple Data Augmentation Strategies\n",
        "augmentation_setups = {\n",
        "    \"basic\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"strong\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Function to Select Model\n",
        "def get_model(model_name, num_classes=20, dropout_rate=0.3):\n",
        "    if model_name == \"ResNet18\":\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.fc.in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    elif model_name == \"MobileNetV2\":\n",
        "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
        "        model.classifier[1] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.classifier[1].in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    elif model_name == \"EfficientNet-B0\":\n",
        "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "        model.classifier[1] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.classifier[1].in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Model not supported\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Custom Dataset Wrapper\n",
        "class VOCMultiLabelDataset(Dataset):\n",
        "    def __init__(self, root=\"./data\", year=\"2012\", image_set=\"train\", transform=None):\n",
        "        self.dataset = datasets.VOCDetection(root=root, year=year, image_set=image_set, download=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        objects = target[\"annotation\"][\"object\"]\n",
        "        if isinstance(objects, dict):  # Convert single object dict to list\n",
        "            objects = [objects]\n",
        "        labels = [obj[\"name\"] for obj in objects]\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Experiment Parameters (Change these)\n",
        "model_name = \"MobileNetV2\"  # Try: \"ResNet18\", \"MobileNetV2\", \"EfficientNet-B0\"\n",
        "dropout_rate = 0.3  # Try: 0.1, 0.3, 0.5\n",
        "augmentation_type = \"strong\"  # Try: \"basic\", \"strong\"\n",
        "image_size = 224  # Try: 128, 224, 256, 384\n",
        "\n",
        "# Set Transform\n",
        "transform = augmentation_setups[augmentation_type]\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = VOCMultiLabelDataset(transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model(model_name, dropout_rate=dropout_rate).to(device)\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    wandb.log({\"Loss\": running_loss / len(train_dataloader)})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "h_loss = hamming_loss(y_true, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "jaccard = jaccard_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Log to wandb\n",
        "wandb.log({\n",
        "    \"Model\": model_name,\n",
        "    \"Dropout Rate\": dropout_rate,\n",
        "    \"Augmentation\": augmentation_type,\n",
        "    \"Image Size\": image_size,\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Hamming Loss\": h_loss,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1-score\": f1,\n",
        "    \"Jaccard Index\": jaccard\n",
        "})\n",
        "\n",
        "# Print Metrics\n",
        "print(f\"Model: {model_name}, Dropout: {dropout_rate}, Augmentation: {augmentation_type}, Image Size: {image_size}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}, Hamming Loss: {h_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Jaccard Index: {jaccard:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PASCAL-VOC2007"
      ],
      "metadata": {
        "id": "-oEikNX8i-67"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxhdzeI7W-A7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5760eb0d-6d30-4fa6-dd1b-39eda969ea11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250309_054606-caqhzmag</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/caqhzmag' target=\"_blank\">efficient-surf-24</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/caqhzmag' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/caqhzmag</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar to ./data/VOCtrainval_06-Nov-2007.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 460M/460M [00:32<00:00, 14.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/VOCtrainval_06-Nov-2007.tar to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.2216, Accuracy: 0.1020\n",
            "Epoch 2/5, Loss: 0.1887, Accuracy: 0.1591\n",
            "Epoch 3/5, Loss: 0.1741, Accuracy: 0.2063\n",
            "Epoch 4/5, Loss: 0.1674, Accuracy: 0.2299\n",
            "Epoch 5/5, Loss: 0.1587, Accuracy: 0.2667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Dataset Selection\n",
        "dataset_name = \"PASCAL-VOC2007\"  # Choose from [\"NUS-WIDE\", \"MS-COCO\", \"PASCAL-VOC2007\", \"VOC2012\", \"Visual Genome\", \"News-500\", \"CUB\"]\n",
        "\n",
        "# Define Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define MultiLabelBinarizer\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])  # Fix NotFittedError\n",
        "\n",
        "# Custom Dataset Class\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, root, dataset_name, transform=None):\n",
        "        if dataset_name == \"VOC2012\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2012\", image_set=\"train\", download=True)\n",
        "        elif dataset_name == \"PASCAL-VOC2007\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2007\", image_set=\"train\", download=True)\n",
        "        else:\n",
        "            raise ValueError(\"Dataset not supported yet!\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        labels = [obj[\"name\"] for obj in target[\"annotation\"][\"object\"]]\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = MultiLabelDataset(root=\"./data\", dataset_name=dataset_name, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define Model Options\n",
        "model_choices = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"mobilenet_v2\": models.mobilenet_v2,\n",
        "    \"vgg16\": models.vgg16,\n",
        "    \"densenet121\": models.densenet121,\n",
        "    \"alexnet\": models.alexnet,\n",
        "    \"googlenet\": models.googlenet\n",
        "}\n",
        "model_name = \"resnet18\"  # Choose model\n",
        "\n",
        "# Define Multi-Label Classification Model\n",
        "class MultiLabelModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=20, dropout_rate=0.5):\n",
        "        super(MultiLabelModel, self).__init__()\n",
        "        self.model = model_choices[model_name](pretrained=True)\n",
        "        if \"fc\" in dir(self.model):\n",
        "            in_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            in_features = self.model.classifier[6].in_features\n",
        "            self.model.classifier[6] = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.model(x))\n",
        "\n",
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiLabelModel(model_name=model_name, num_classes=20, dropout_rate=0.3).to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "train_losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        predictions = (outputs > 0.5).float()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "    avg_loss = running_loss / len(train_dataloader)\n",
        "    accuracy = accuracy_score(np.array(y_true), np.array(y_pred))\n",
        "    train_losses.append(avg_loss)\n",
        "    accuracies.append(accuracy)\n",
        "    wandb.log({\"Loss\": avg_loss, \"Accuracy\": accuracy})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Plot Loss and Accuracy Curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, marker='o', linestyle='-', color='b', label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), accuracies, marker='s', linestyle='-', color='r', label='Training Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metrics\")\n",
        "plt.title(\"Training Loss and Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support, jaccard_score\n",
        "\n",
        "# Initialize Weights & Biases (wandb)\n",
        "wandb.init(project=\"multi-label-image-classification\")\n",
        "\n",
        "# Dataset Selection\n",
        "dataset_name = \"PASCAL-VOC2007\"  # Choose from [\"NUS-WIDE\", \"MS-COCO\", \"PASCAL-VOC2007\", \"VOC2012\", \"Visual Genome\", \"News-500\", \"CUB\"]\n",
        "\n",
        "# Define Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define MultiLabelBinarizer\n",
        "VOC_CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "mlb = MultiLabelBinarizer(classes=VOC_CLASSES)\n",
        "mlb.fit([VOC_CLASSES])  # Fix NotFittedError\n",
        "\n",
        "# Custom Dataset Class\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, root, dataset_name, transform=None):\n",
        "        if dataset_name == \"VOC2012\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2012\", image_set=\"train\", download=True)\n",
        "        elif dataset_name == \"PASCAL-VOC2007\":\n",
        "            self.dataset = datasets.VOCDetection(root=root, year=\"2007\", image_set=\"train\", download=True)\n",
        "        else:\n",
        "            raise ValueError(\"Dataset not supported yet!\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, target = self.dataset[index]\n",
        "        labels = [obj[\"name\"] for obj in target[\"annotation\"][\"object\"]]\n",
        "        labels = mlb.transform([labels])[0].astype(np.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(labels)\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = MultiLabelDataset(root=\"./data\", dataset_name=dataset_name, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define Model Options\n",
        "model_choices = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"mobilenet_v2\": models.mobilenet_v2,\n",
        "    \"vgg16\": models.vgg16,\n",
        "    \"densenet121\": models.densenet121,\n",
        "    \"alexnet\": models.alexnet,\n",
        "    \"googlenet\": models.googlenet\n",
        "}\n",
        "model_name = \"googlenet\"  # Choose model\n",
        "\n",
        "# Define Multi-Label Classification Model\n",
        "class MultiLabelModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=20, dropout_rate=0.5):\n",
        "        super(MultiLabelModel, self).__init__()\n",
        "        self.model = model_choices[model_name](pretrained=True)\n",
        "        if \"fc\" in dir(self.model):\n",
        "            in_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            in_features = self.model.classifier[6].in_features\n",
        "            self.model.classifier[6] = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.model(x))\n",
        "\n",
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiLabelModel(model_name=model_name, num_classes=20, dropout_rate=0.3).to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "train_losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        predictions = (outputs > 0.5).float()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "    avg_loss = running_loss / len(train_dataloader)\n",
        "    accuracy = accuracy_score(np.array(y_true), np.array(y_pred))\n",
        "    train_losses.append(avg_loss)\n",
        "    accuracies.append(accuracy)\n",
        "    wandb.log({\"Loss\": avg_loss, \"Accuracy\": accuracy})\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Plot Loss and Accuracy Curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, marker='o', linestyle='-', color='b', label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), accuracies, marker='s', linestyle='-', color='r', label='Training Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metrics\")\n",
        "plt.title(\"Training Loss and Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nSTt-RtUG4p-",
        "outputId": "4b540ab9-4625-4801-cfd0-77becfaa7eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250309_181456-rm5auvs3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/rm5auvs3' target=\"_blank\">celestial-feather-25</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/rm5auvs3' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi-label-image-classification/runs/rm5auvs3</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUS WIDE dataset"
      ],
      "metadata": {
        "id": "_MgQ2z27bKm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"xinleili/nuswide\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ffSZlvZtIa",
        "outputId": "b3b626eb-b011-4cd5-db5b-06c0fa300437"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xinleili/nuswide?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.77G/5.77G [00:55<00:00, 113MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/xinleili/nuswide/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import wandb\n",
        "\n",
        "##############################################\n",
        "# Function to create train.csv and val.csv by scanning the dataset_dir recursively.\n",
        "##############################################\n",
        "def create_csv_files(dataset_dir, train_csv_path, val_csv_path, classes, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Recursively scans the dataset_dir for image files,\n",
        "    generates random multi-label annotations (for demo purposes), and splits them into\n",
        "    training and validation CSV files.\n",
        "    \"\"\"\n",
        "    # Use recursive globbing to find images in all subdirectories.\n",
        "    img_extensions = (\"*.jpg\", \"*.jpeg\", \"*.png\")\n",
        "    image_files = []\n",
        "    for ext in img_extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(dataset_dir, \"**\", ext), recursive=True))\n",
        "    image_files = sorted(image_files)\n",
        "\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(f\"No image files found in {dataset_dir} (searched recursively)\")\n",
        "\n",
        "    # Generate a random multi-label for each image.\n",
        "    # For demonstration, assign each image between 1 and 3 random labels.\n",
        "    data = []\n",
        "    for img_path in image_files:\n",
        "        num_labels = random.randint(1, min(3, len(classes)))\n",
        "        labels = random.sample(classes, num_labels)\n",
        "        labels_str = \",\".join(labels)\n",
        "        data.append({\"image_path\": img_path, \"labels\": labels_str})\n",
        "\n",
        "    # Shuffle and split data.\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * train_ratio)\n",
        "    train_data = data[:split_idx]\n",
        "    val_data = data[split_idx:]\n",
        "\n",
        "    # Save to CSV.\n",
        "    pd.DataFrame(train_data).to_csv(train_csv_path, index=False)\n",
        "    pd.DataFrame(val_data).to_csv(val_csv_path, index=False)\n",
        "    print(f\"Created {len(train_data)} training samples and {len(val_data)} validation samples.\")\n",
        "\n",
        "##############################################\n",
        "# Custom Dataset for Multi-label Classification\n",
        "##############################################\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, classes, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (str): Path to the CSV file with annotations.\n",
        "            classes (list): List of all possible class names.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        labels_str = row['labels']  # Expected format: \"cat,dog,bird\", etc.\n",
        "        labels_list = labels_str.split(',')\n",
        "        # Create a multi-hot vector.\n",
        "        label_vector = np.zeros(len(self.classes), dtype=np.float32)\n",
        "        for label in labels_list:\n",
        "            label = label.strip()\n",
        "            if label in self.classes:\n",
        "                label_vector[self.classes.index(label)] = 1.0\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label_vector)\n",
        "\n",
        "##############################################\n",
        "# Multi-label Model based on ResNet50\n",
        "##############################################\n",
        "class MultiLabelResNet(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0.5):\n",
        "        super(MultiLabelResNet, self).__init__()\n",
        "        self.base_model = models.resnet50(pretrained=True)\n",
        "        num_ftrs = self.base_model.fc.in_features\n",
        "        self.base_model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "##############################################\n",
        "# Ranking Loss for Multi-label Learning\n",
        "##############################################\n",
        "class RankingLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(RankingLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0.0\n",
        "        batch_size = outputs.size(0)\n",
        "        for i in range(batch_size):\n",
        "            pos_idx = (targets[i] == 1).nonzero(as_tuple=False).squeeze()\n",
        "            neg_idx = (targets[i] == 0).nonzero(as_tuple=False).squeeze()\n",
        "            if pos_idx.dim() == 0:\n",
        "                pos_idx = pos_idx.unsqueeze(0)\n",
        "            if neg_idx.dim() == 0:\n",
        "                neg_idx = neg_idx.unsqueeze(0)\n",
        "            pos_scores = outputs[i][pos_idx]\n",
        "            neg_scores = outputs[i][neg_idx]\n",
        "            for pos in pos_scores:\n",
        "                for neg in neg_scores:\n",
        "                    loss += torch.clamp(self.margin - (pos - neg), min=0)\n",
        "        return loss / batch_size\n",
        "\n",
        "##############################################\n",
        "# Combined Loss: Ranking Loss + BCE Loss\n",
        "##############################################\n",
        "def combined_loss(outputs, targets, ranking_loss_fn, bce_loss_fn, alpha=0.5):\n",
        "    loss_ranking = ranking_loss_fn(outputs, targets)\n",
        "    loss_bce = bce_loss_fn(outputs, targets)\n",
        "    return alpha * loss_ranking + (1 - alpha) * loss_bce\n",
        "\n",
        "##############################################\n",
        "# Validation Function to Compute Metrics\n",
        "##############################################\n",
        "def validate(model, val_loader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    exact_match = 0\n",
        "    hamming_loss_total = 0.0\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = bce_loss_fn(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds = (preds > threshold).float()\n",
        "            exact_match += (preds == labels).all(dim=1).sum().item()\n",
        "            sample_hamming = (preds != labels).sum(dim=1) / labels.size(1)\n",
        "            hamming_loss_total += sample_hamming.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    exact_match_ratio = exact_match / total_samples\n",
        "    avg_hamming_loss = hamming_loss_total / total_samples\n",
        "    return avg_loss, exact_match_ratio, avg_hamming_loss\n",
        "\n",
        "##############################################\n",
        "# Main Training and Evaluation Loop\n",
        "##############################################\n",
        "def main():\n",
        "    # Define the dataset directory for NUSWIDE.\n",
        "    dataset_dir = \"/root/.cache/kagglehub/datasets/xinleili/nuswide/versions/1\"\n",
        "    csv_train_path = os.path.join(dataset_dir, \"train.csv\")\n",
        "    csv_val_path   = os.path.join(dataset_dir, \"val.csv\")\n",
        "\n",
        "    # Define the classes (for simulation/demo purposes).\n",
        "    classes = [\"cat\", \"dog\", \"bird\", \"fruit\", \"vegetable\", \"flower\"]\n",
        "\n",
        "    # Create CSV files if they do not exist.\n",
        "    if not os.path.exists(csv_train_path) or not os.path.exists(csv_val_path):\n",
        "        print(\"CSV files not found. Creating train.csv and val.csv from dataset images...\")\n",
        "        create_csv_files(dataset_dir, csv_train_path, csv_val_path, classes, train_ratio=0.8)\n",
        "\n",
        "    # Configuration parameters.\n",
        "    config_dict = {\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": \"ResNet50\",\n",
        "        \"hidden_layers\": 3,          # For naming only.\n",
        "        \"activation\": \"ReLU\",        # For naming only.\n",
        "        \"data_augmentation\": \"Resize+RandomHorizontalFlip\",\n",
        "        \"dropout_rate\": 0.5,\n",
        "        \"image_size\": 224,\n",
        "        \"loss_alpha\": 0.5,           # Weight for ranking loss vs. BCE loss.\n",
        "        \"csv_train\": csv_train_path,\n",
        "        \"csv_val\": csv_val_path,\n",
        "        \"classes\": classes\n",
        "    }\n",
        "\n",
        "    # Build a descriptive run name.\n",
        "    run_name = f\"hl_{config_dict['hidden_layers']}_bs_{config_dict['batch_size']}_ac_{config_dict['activation']}\"\n",
        "\n",
        "    # Initialize wandb.\n",
        "    wandb.init(project=\"multi_label_classification\", name=run_name, config=config_dict)\n",
        "    config = wandb.config\n",
        "\n",
        "    # Data transformations.\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets.\n",
        "    train_dataset = MultiLabelDataset(csv_file=config.csv_train, classes=config.classes, transform=train_transforms)\n",
        "    val_dataset   = MultiLabelDataset(csv_file=config.csv_val, classes=config.classes, transform=val_transforms)\n",
        "\n",
        "    # Data loaders.\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_classes = len(config.classes)\n",
        "\n",
        "    # Initialize model.\n",
        "    model = MultiLabelResNet(num_classes, dropout_rate=config.dropout_rate).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    ranking_loss_fn = RankingLoss(margin=1.0)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    epochs_list = []\n",
        "\n",
        "    # Training loop.\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = combined_loss(outputs, labels, ranking_loss_fn, bce_loss_fn, alpha=config.loss_alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_dataset)\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch})\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "\n",
        "        # Validation.\n",
        "        val_loss, exact_match_ratio, avg_hamming_loss = validate(model, val_loader, device)\n",
        "        wandb.log({\n",
        "            \"val_loss\": val_loss,\n",
        "            \"exact_match_ratio\": exact_match_ratio,\n",
        "            \"avg_hamming_loss\": avg_hamming_loss,\n",
        "            \"epoch\": epoch\n",
        "        })\n",
        "        val_loss_list.append(val_loss)\n",
        "        epochs_list.append(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Exact Match: {exact_match_ratio:.4f}, Hamming Loss: {avg_hamming_loss:.4f}\")\n",
        "\n",
        "    # Plot and log loss curves.\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
        "    plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "    plt.show()\n",
        "\n",
        "    # Save the model.\n",
        "    torch.save(model.state_dict(), \"multi_label_resnet.pth\")\n",
        "    wandb.save(\"multi_label_resnet.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "Qfg-59HOeg8d",
        "outputId": "9c663549-7648-4539-dace-21e77bc3d27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files not found. Creating train.csv and val.csv from dataset images...\n",
            "Created 215723 training samples and 53931 validation samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250310_090810-nl7g8moi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/nl7g8moi' target=\"_blank\">hl_3_bs_16_ac_ReLU</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/nl7g8moi' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/nl7g8moi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 120MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 4.0295, Val Loss: 0.6415, Exact Match: 0.0006, Hamming Loss: 0.3334\n",
            "Epoch 2/10, Train Loss: 4.0083, Val Loss: 0.6447, Exact Match: 0.0004, Hamming Loss: 0.3333\n",
            "Epoch 3/10, Train Loss: 4.0035, Val Loss: 0.6406, Exact Match: 0.0002, Hamming Loss: 0.3332\n",
            "Epoch 4/10, Train Loss: 3.9991, Val Loss: 0.6412, Exact Match: 0.0000, Hamming Loss: 0.3329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Genome"
      ],
      "metadata": {
        "id": "b3uV5NTiklD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mathurinache/visual-genome\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8tXYSQNin-_",
        "outputId": "a7306b59-9099-4943-d5ca-83d4ae1bdf25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mathurinache/visual-genome?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 129M/129M [00:02<00:00, 57.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mathurinache/visual-genome/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6v6RVFjJoc",
        "outputId": "64579929-91ca-4aa6-d98e-8b57618f16dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attribute_synsets.json  objects.json         relationship_alias.txt  relationship_synsets.json\n",
            "object_alias.txt        object_synsets.json  relationships.json      \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import wandb\n",
        "\n",
        "##############################################\n",
        "# Helper function to find a file recursively in a directory.\n",
        "##############################################\n",
        "def find_file(filename, directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "##############################################\n",
        "# Helper function to fix image paths.\n",
        "##############################################\n",
        "def fix_image_path(rel_path, base_dir):\n",
        "    path = os.path.join(base_dir, rel_path)\n",
        "    if os.path.exists(path):\n",
        "        return path\n",
        "    alt_path = os.path.join(base_dir, \"images\", rel_path)\n",
        "    if os.path.exists(alt_path):\n",
        "        return alt_path\n",
        "    return path\n",
        "\n",
        "##############################################\n",
        "# Build a mapping from image ID to image file path.\n",
        "##############################################\n",
        "def build_image_dict(dataset_dir):\n",
        "    # Try \"images\" subfolder first; if not present, use dataset_dir.\n",
        "    images_folder = os.path.join(dataset_dir, \"images\")\n",
        "    if not os.path.exists(images_folder):\n",
        "        images_folder = dataset_dir\n",
        "    # Search common image extensions.\n",
        "    image_files = glob.glob(os.path.join(images_folder, \"*.jpg\")) + \\\n",
        "                  glob.glob(os.path.join(images_folder, \"*.jpeg\")) + \\\n",
        "                  glob.glob(os.path.join(images_folder, \"*.png\"))\n",
        "    image_dict = {}\n",
        "    for path in image_files:\n",
        "        basename = os.path.basename(path)\n",
        "        img_id = os.path.splitext(basename)[0]\n",
        "        image_dict[img_id] = path\n",
        "    if not image_dict:\n",
        "        print(f\"Warning: No images found in {images_folder}. Dummy images will be used.\")\n",
        "    return image_dict\n",
        "\n",
        "##############################################\n",
        "# Function to create a dummy image and return its path.\n",
        "##############################################\n",
        "def get_dummy_image(dataset_dir, size=(224,224), color=(0,0,0)):\n",
        "    dummy_path = os.path.join(dataset_dir, \"dummy.jpg\")\n",
        "    if not os.path.exists(dummy_path):\n",
        "        dummy_img = Image.new(\"RGB\", size, color)\n",
        "        dummy_img.save(dummy_path)\n",
        "    return dummy_path\n",
        "\n",
        "##############################################\n",
        "# Function to create train.csv and val.csv for Visual Genome using objects.json.\n",
        "##############################################\n",
        "def create_csv_files_vg(dataset_dir, train_csv_path, val_csv_path, train_ratio=0.8, top_k=50):\n",
        "    \"\"\"\n",
        "    Reads object annotations from objects.json (from Visual Genome v1.4)\n",
        "    and creates train.csv and val.csv for multi-label classification.\n",
        "\n",
        "    It uses the annotation file objects.json and, if available, object_alias.txt to map synonyms.\n",
        "    Then, it counts the frequency of object names, retains only the top_k most frequent,\n",
        "    filters each image’s label set accordingly, shuffles, and splits into train/val CSV files.\n",
        "\n",
        "    If image files are not found, a dummy image is used.\n",
        "    \"\"\"\n",
        "    # Locate the objects annotation file.\n",
        "    objects_file = find_file(\"objects.json\", dataset_dir)\n",
        "    if not objects_file:\n",
        "        raise FileNotFoundError(\"objects.json not found in the dataset directory.\")\n",
        "\n",
        "    with open(objects_file, 'r') as f:\n",
        "        objects_data = json.load(f)\n",
        "\n",
        "    # Build a mapping from image ID to image file path.\n",
        "    image_dict = build_image_dict(dataset_dir)\n",
        "\n",
        "    # Read alias mapping from object_alias.txt if available.\n",
        "    alias_file = find_file(\"object_alias.txt\", dataset_dir)\n",
        "    alias_mapping = {}\n",
        "    if alias_file:\n",
        "        with open(alias_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                synonyms = line.strip().split(\",\")\n",
        "                if synonyms:\n",
        "                    canonical = synonyms[0].strip().lower()\n",
        "                    for syn in synonyms:\n",
        "                        alias_mapping[syn.strip().lower()] = canonical\n",
        "\n",
        "    freq = {}\n",
        "    rows = []\n",
        "    # Process each annotation entry.\n",
        "    for entry in objects_data:\n",
        "        image_id = str(entry.get(\"image_id\"))\n",
        "        obj_list = entry.get(\"objects\", [])\n",
        "        labels_set = set()\n",
        "        for obj in obj_list:\n",
        "            names = obj.get(\"names\", [])\n",
        "            for name in names:\n",
        "                name = name.lower().strip()\n",
        "                if name in alias_mapping:\n",
        "                    name = alias_mapping[name]\n",
        "                labels_set.add(name)\n",
        "                freq[name] = freq.get(name, 0) + 1\n",
        "        # Even if no labels, add the row (it may later be filtered).\n",
        "        label_str = \",\".join(sorted(labels_set))\n",
        "        if image_id in image_dict:\n",
        "            image_path = image_dict[image_id]\n",
        "        else:\n",
        "            image_path = get_dummy_image(dataset_dir)\n",
        "        rows.append({\"image_path\": image_path, \"labels\": label_str})\n",
        "\n",
        "    if not rows:\n",
        "        raise FileNotFoundError(\"No annotation rows could be generated from objects.json.\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    # Determine top_k most frequent labels.\n",
        "    sorted_classes = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_classes = set([cls for cls, count in sorted_classes[:top_k]])\n",
        "\n",
        "    def filter_labels(label_str):\n",
        "        labels = label_str.split(\",\")\n",
        "        filtered = [l for l in labels if l in top_classes]\n",
        "        return \",\".join(sorted(filtered))\n",
        "\n",
        "    df[\"labels\"] = df[\"labels\"].apply(filter_labels)\n",
        "    # Remove rows with empty label set.\n",
        "    df = df[df[\"labels\"] != \"\"]\n",
        "\n",
        "    # Final list of classes used.\n",
        "    classes = sorted(set(\",\".join(df[\"labels\"].tolist()).split(\",\")))\n",
        "\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    split_idx = int(len(df) * train_ratio)\n",
        "    train_df = df.iloc[:split_idx]\n",
        "    val_df = df.iloc[split_idx:]\n",
        "\n",
        "    train_df.to_csv(train_csv_path, index=False)\n",
        "    val_df.to_csv(val_csv_path, index=False)\n",
        "    print(f\"Created {len(train_df)} training samples and {len(val_df)} validation samples for Visual Genome.\")\n",
        "\n",
        "    return classes\n",
        "\n",
        "##############################################\n",
        "# Custom Dataset for Multi-label Classification\n",
        "##############################################\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, classes, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        label_str = row['labels'].strip()\n",
        "        label_vector = np.zeros(len(self.classes), dtype=np.float32)\n",
        "        for label in label_str.split(\",\"):\n",
        "            if label in self.classes:\n",
        "                label_vector[self.classes.index(label)] = 1.0\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label_vector)\n",
        "\n",
        "##############################################\n",
        "# Multi-label Model based on ResNet50\n",
        "##############################################\n",
        "class MultiLabelResNet(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0.5):\n",
        "        super(MultiLabelResNet, self).__init__()\n",
        "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.base_model.fc.in_features\n",
        "        self.base_model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "##############################################\n",
        "# Ranking Loss for Multi-label Learning\n",
        "##############################################\n",
        "class RankingLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(RankingLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0.0\n",
        "        batch_size = outputs.size(0)\n",
        "        for i in range(batch_size):\n",
        "            pos_idx = (targets[i] == 1).nonzero(as_tuple=False).squeeze()\n",
        "            neg_idx = (targets[i] == 0).nonzero(as_tuple=False).squeeze()\n",
        "            if pos_idx.dim() == 0:\n",
        "                pos_idx = pos_idx.unsqueeze(0)\n",
        "            if neg_idx.dim() == 0:\n",
        "                neg_idx = neg_idx.unsqueeze(0)\n",
        "            pos_scores = outputs[i][pos_idx]\n",
        "            neg_scores = outputs[i][neg_idx]\n",
        "            for pos in pos_scores:\n",
        "                for neg in neg_scores:\n",
        "                    loss += torch.clamp(self.margin - (pos - neg), min=0)\n",
        "        return loss / batch_size\n",
        "\n",
        "##############################################\n",
        "# Combined Loss: Ranking Loss + BCE Loss\n",
        "##############################################\n",
        "def combined_loss(outputs, targets, ranking_loss_fn, bce_loss_fn, alpha=0.5):\n",
        "    loss_ranking = ranking_loss_fn(outputs, targets)\n",
        "    loss_bce = bce_loss_fn(outputs, targets)\n",
        "    return alpha * loss_ranking + (1 - alpha) * loss_bce\n",
        "\n",
        "##############################################\n",
        "# Validation Function to Compute Metrics\n",
        "##############################################\n",
        "def validate(model, val_loader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    exact_match = 0\n",
        "    hamming_loss_total = 0.0\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = bce_loss_fn(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds = (preds > threshold).float()\n",
        "            exact_match += (preds == labels).all(dim=1).sum().item()\n",
        "            sample_hamming = (preds != labels).sum(dim=1) / labels.size(1)\n",
        "            hamming_loss_total += sample_hamming.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    exact_match_ratio = exact_match / total_samples\n",
        "    avg_hamming_loss = hamming_loss_total / total_samples\n",
        "    return avg_loss, exact_match_ratio, avg_hamming_loss\n",
        "\n",
        "##############################################\n",
        "# Main Training and Evaluation Loop\n",
        "##############################################\n",
        "def main():\n",
        "    # Set dataset_dir to your Visual Genome dataset directory.\n",
        "    dataset_dir = \"/root/.cache/kagglehub/datasets/mathurinache/visual-genome/versions/1\"\n",
        "    csv_train_path = os.path.join(dataset_dir, \"train.csv\")\n",
        "    csv_val_path = os.path.join(dataset_dir, \"val.csv\")\n",
        "\n",
        "    if not os.path.exists(csv_train_path) or not os.path.exists(csv_val_path):\n",
        "        print(\"CSV files not found. Creating train.csv and val.csv from Visual Genome objects...\")\n",
        "        classes = create_csv_files_vg(dataset_dir, csv_train_path, csv_val_path, train_ratio=0.8, top_k=50)\n",
        "    else:\n",
        "        df = pd.read_csv(csv_train_path)\n",
        "        classes = sorted(set(\",\".join(df[\"labels\"].tolist()).split(\",\")))\n",
        "\n",
        "    config_dict = {\n",
        "        \"epochs\": 3,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": \"ResNet50\",\n",
        "        \"hidden_layers\": 3,\n",
        "        \"activation\": \"ReLU\",\n",
        "        \"data_augmentation\": \"Resize+RandomHorizontalFlip\",\n",
        "        \"dropout_rate\": 0.5,\n",
        "        \"image_size\": 224,\n",
        "        \"loss_alpha\": 0.5,\n",
        "        \"csv_train\": csv_train_path,\n",
        "        \"csv_val\": csv_val_path,\n",
        "        \"classes\": classes\n",
        "    }\n",
        "\n",
        "    run_name = f\"hl_{config_dict['hidden_layers']}_bs_{config_dict['batch_size']}_ac_{config_dict['activation']}\"\n",
        "    wandb.init(project=\"multi_label_classification\", name=run_name, config=config_dict)\n",
        "    config = wandb.config\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = MultiLabelDataset(csv_file=config.csv_train, classes=config.classes, transform=train_transforms)\n",
        "    val_dataset = MultiLabelDataset(csv_file=config.csv_val, classes=config.classes, transform=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_classes = len(config.classes)\n",
        "\n",
        "    model = MultiLabelResNet(num_classes, dropout_rate=config.dropout_rate).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    ranking_loss_fn = RankingLoss(margin=1.0)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    epochs_list = []\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = combined_loss(outputs, labels, ranking_loss_fn, bce_loss_fn, alpha=config.loss_alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_dataset)\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch})\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "\n",
        "        val_loss, exact_match_ratio, avg_hamming_loss = validate(model, val_loader, device)\n",
        "        wandb.log({\n",
        "            \"val_loss\": val_loss,\n",
        "            \"exact_match_ratio\": exact_match_ratio,\n",
        "            \"avg_hamming_loss\": avg_hamming_loss,\n",
        "            \"epoch\": epoch\n",
        "        })\n",
        "        val_loss_list.append(val_loss)\n",
        "        epochs_list.append(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Exact Match: {exact_match_ratio:.4f}, Hamming Loss: {avg_hamming_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
        "    plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "    plt.show()\n",
        "\n",
        "    torch.save(model.state_dict(), \"multi_label_resnet.pth\")\n",
        "    wandb.save(\"multi_label_resnet.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "sffSZgzcjCzT",
        "outputId": "ffe387ca-f5de-4fd1-b842-dafb94f21101"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV files not found. Creating train.csv and val.csv from Visual Genome objects...\n",
            "Warning: No images found in /root/.cache/kagglehub/datasets/mathurinache/visual-genome/versions/1. Dummy images will be used.\n",
            "Created 82968 training samples and 20743 validation samples for Visual Genome.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahi77\u001b[0m (\u001b[33mshahi77-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250310_150918-6towe5in</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/6towe5in' target=\"_blank\">hl_3_bs_16_ac_ReLU</a></strong> to <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/6towe5in' target=\"_blank\">https://wandb.ai/shahi77-national-institute-of-technology-hamirpur/multi_label_classification/runs/6towe5in</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 135MB/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlhss8YKf2bMSV1sfXzI10",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}